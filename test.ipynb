{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports such as Open CV library, NumPy Library, os module, Pandas etc.\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Import tensorflow library the most commonly used framework for machine learning models\n",
    "import tensorflow as tf\n",
    "\n",
    "#prints the version of TensorFlow Library Installed\n",
    "print('Tensorflow version :' , tf.__version__)\n",
    "\n",
    "#Imports keras module from the tensorflow library. Keras is a high-level neural network used for training machine learning models.\n",
    "from tensorflow import keras\n",
    "\n",
    "#prints the version of keras installed\n",
    "print('keras version:' , keras.__version__)\n",
    "\n",
    "#Imports element Tree used to read .xml files.\n",
    "from xml.etree import ElementTree\n",
    "\n",
    "#Assigns directory paths to both the annotation files and image files\n",
    "image_Dir = './images'\n",
    "annotations_Dir = './annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#creates an empty list where .xml files will be stored.\n",
    "annot_files = []\n",
    "\n",
    "#appends annotation .xml files to the anno_files list in a for loop\n",
    "for file in glob.glob(annotations_Dir + '\\*.xml'):\n",
    "    annot_files.append(os.path.abspath(file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtains the list of file names in the Images file and assigns them to the image directory \n",
    "image_files_list = os.listdir(image_Dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#information will be used to extract information from the .xml annotation files files\n",
    "\n",
    "information = {\n",
    "    #includes the data collected from the .xml fies\n",
    "    #minimum x value\n",
    "    'xmin' : [],\n",
    "    'ymax' : [],#maximum y value\n",
    "    'label': [],#label (name of class)\n",
    "    'xmax' : [],#maximum x value\n",
    "    'ymin' : [],#minimum y value\n",
    "    'w': [],#width\n",
    "    'h': [],#height\n",
    "    'imgfile' : [],#name of image file\n",
    "    'annotfile':[],#annotation file name\n",
    "    'depth' :[]#depth of image\n",
    "}\n",
    "\n",
    "for annot_file in (annot_files):\n",
    "    #extracts information such as width, height, and depth of image\n",
    "    xmlTree = ElementTree.parse(annot_file)\n",
    "    for node in xmlTree.iter():\n",
    "        if 'folder' in node.tag:\n",
    "            imgfoldername = node.text\n",
    "        elif 'filename' in node.tag:\n",
    "            img_file_name = node.text\n",
    "        if 'size' in node.tag:\n",
    "            for child_node in list(node):\n",
    "                if 'width' in child_node.tag:\n",
    "                    w = int(round(float(child_node.text)))\n",
    "                if 'height' in child_node.tag:\n",
    "                    h = int(round(float(child_node.text)))   \n",
    "                if 'depth' in child_node.tag:\n",
    "                    depth = int(round(float(child_node.text)))\n",
    "        #extracts information like label, xmin, ymin, ymax\n",
    "        #stores all of the information into the information dictionary.\n",
    "        if 'object' in node.tag:\n",
    "            for obj_child_node in list(node):\n",
    "                if 'name' in obj_child_node.tag:\n",
    "                    name = obj_child_node.text\n",
    "                    information['label']+=[name]\n",
    "                    information['w']+=[w]\n",
    "                    information['h'] += [h]\n",
    "                    information['depth']+= [depth]\n",
    "                    information['imgfile']+= ['./'+ imgfoldername + '/'+ img_file_name]\n",
    "                    information['annotfile']+=[annot_file]\n",
    "        #this code reads the xml files, and extracts information about the image file. \n",
    "        \n",
    "                if 'bndbox' in obj_child_node.tag:\n",
    "                    for bndbox_child in list(obj_child_node):\n",
    "                        if 'xmin' in bndbox_child.tag:\n",
    "                            xmin = int(round(float(bndbox_child.text)))\n",
    "                            information['xmin']+=[xmin]\n",
    "                        if 'ymin' in bndbox_child.tag:\n",
    "                            ymin = int(round(float(bndbox_child.text)))\n",
    "                            information['ymin']+=[ymin]\n",
    "        #It stores the image dimensions, coordinations, and file path\n",
    "        #the extracted information will be used for training the model and evaluation.\n",
    "                        if 'xmax' in bndbox_child.tag:\n",
    "                            xmax = int(round(float(bndbox_child.text)))\n",
    "                            information['xmax']+=[xmax]\n",
    "                        if 'ymax' in bndbox_child.tag:\n",
    "                            ymax = int(round(float(bndbox_child.text)))\n",
    "                            information['ymax']+=[ymax]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code converts the information dictionary created previously\n",
    "#and converts it into a pandas DataFrame named 'information_df'\n",
    "#Each key created becomes a column and the data is listed for each\n",
    "#key\n",
    "information_df = pd.DataFrame(information)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes an image input and displays it using matplotlub\n",
    "\n",
    "def render(image):\n",
    "    plt.figure(figsize =(12,8) )\n",
    "    #the specific size will be 12x8\n",
    "#the function is then displayed on the screen.\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def convert_RGB (image):\n",
    "    #function converts BGR image to the RGB color space. This format\n",
    "    #is used by most visualiztion tools\n",
    "    return cv2.cvtColor(image,cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tests out if the code is working so far.\n",
    "img_index = 10\n",
    "#assigns the index of the image that will be used in this example\n",
    "\n",
    "#gets the value from the imgfile column in the information_df dataframe. This is the file path to the image\n",
    "temp_img_file_name=information_df['imgfile'].iloc[img_index]\n",
    "\n",
    "#this reads teh image location in the image stored in the temp_img_file name\n",
    "img_tmp = cv2.imread(temp_img_file_name)\n",
    "\n",
    "#conversts the image and displays the image using mathplot libe\n",
    "render(convert_RGB(img_tmp))\n",
    " \n",
    "#gets the shape of the image (h,w,number of color channels.)\n",
    "img_tmp.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#crops the image using the values from the _df chart\n",
    "#gets the xmin value \n",
    "x = information_df['xmin'].iloc[img_index]\n",
    "#gets the ymin value\n",
    "y = information_df['ymin'].iloc[img_index]\n",
    "#gets the xmax value\n",
    "width = information_df['xmax'].iloc[img_index]\n",
    "#gets the y max value\n",
    "height = information_df['ymax'].iloc[img_index]\n",
    "\n",
    "#crops the image using the regions specificed by the coordinates collected.\n",
    "crop_image_tmp = img_tmp[y:height, x:width]\n",
    "#converts the image to the correct colorspace\n",
    "render(convert_RGB(crop_image_tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#creates a path for a directory name \"working\"\n",
    "work_dir = os.path.abspath('./working')\n",
    "#creates a 'working' directory using the path specified in the work_dir\n",
    "os.mkdir(work_dir)\n",
    "#creates an path for directory inside the working directory called cropped\n",
    "cropped_dir = os.path.join(work_dir, 'cropped')\n",
    "#creates the cropped directory within the working directory.\n",
    "os.mkdir(cropped_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a new column in the info_df dataframe that stores all of the cropped images\n",
    "information_df['cropped_img'] = information_df['imgfile']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop that loops over reach row in the info_df data frame \n",
    "for index in range(len(information_df)):\n",
    "#retrieves file names from the column at the index\n",
    "    img_file_name = information_df['imgfile'].iloc[index]\n",
    "\n",
    "#extracts the base filename and splits the file name removing it.\n",
    "    no_extension_file_name = os.path.basename(img_file_name).split('.')[0] \n",
    "#creates file name for the cropped image combing the other paths.\n",
    "    cropped_file_name=os.path.join(cropped_dir, no_extension_file_name + '-'+ str(index)+ '.png')\n",
    "#includes this into the dataframe\n",
    "    information_df['cropped_img'].iloc[index] = cropped_file_name\n",
    "\n",
    "    img_tmp = cv2.imread(temp_img_file_name)\n",
    "\n",
    "#retreives the coordinates of the min, max, min, max of the x and y coordinates\n",
    "    x = information_df['xmin'].iloc[img_index]\n",
    "    y = information_df['ymin'].iloc[img_index]\n",
    "    #max, min, max of the x and y coordinates\n",
    "    width = information_df['xmax'].iloc[img_index]\n",
    "    height = information_df['ymax'].iloc[img_index]\n",
    "\n",
    "#creates the cropped image using the specific coordinates provided \n",
    "    crop_image_tmp = img_tmp[y:height, x:width]\n",
    "#saves the cropped image to the path\n",
    "    cv2.imwrite(cropped_file_name, crop_image_tmp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renders a specific cropped image from the cropped directory \n",
    "\n",
    "render(cv2.imread(information_df['cropped_img'].iloc[img_index]))\n",
    "#used to understand what the progress of the code is like so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilzies function from scikit-larn to split the dataset into training and testing dataset\n",
    "\n",
    "#module used to split the datset\n",
    "from sklearn.model_selection import train_test_split\n",
    "#splits dat into 30% testing and 70% training data\n",
    "#information_df has the data to be split\n",
    "training_df, test_df = train_test_split(information_df , test_size = 0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a list named classes that will have the labels of the images in the training_df data\n",
    "classes = list(training_df['label'].unique())\n",
    "classes\n",
    "#there are 3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts the occurence of each different class and how many images are in each class\n",
    "training_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a table with the information of the amount of photos for each type\n",
    "labels_table = pd.DataFrame(training_df['label'].value_counts()).reset_index()\n",
    "#will have the label name and the count\n",
    "labels_table.rename(columns={'index': 'label', 'label': 'count'}, inplace = False)\n",
    "#prints the table\n",
    "labels_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#arrays that store the width and height of the image\n",
    "image_width= []\n",
    "image_height=[]\n",
    "\n",
    "for index in range(len(training_df)):\n",
    "   \n",
    "   #retrieves the cropped file name for the the row and column\n",
    "   cropped_image = cv2.imread(cropped_file_name)\n",
    "#appends the width and height of a specific image\n",
    "   image_width.append(cropped_image.shape[0])\n",
    "   image_height.append(cropped_image.shape[1])\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates the dimensions of the images using the median values of the width and height lists. \n",
    "image_expected = (int(np.median(image_width)), int(np.median(image_height)))\n",
    "#this allows for the data to be standardized because they will be of the same size\n",
    "#in the machine learning \n",
    "image_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the exptedted shape of the image used for the model\n",
    "shape = [int(np.median(image_width)), int (np.median(image_height)),3]\n",
    "#gathers the median size for w and h\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports the imageDatagenerator from Keras allowing for PREPROCESSING\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#rescales the pixel values to a range [0,1]\n",
    "training_generator = ImageDataGenerator(rescale=1. / 255., validation_split=0.30)\n",
    "\n",
    "train_generator = training_generator.flow_from_dataframe(\n",
    "    #creates a generator to house the training data\n",
    "    #holds labels\n",
    "    dataframe=training_df,\n",
    "    #where images are located\n",
    "    directory='./',  \n",
    "    x_col='cropped_img',  #column of the file path\n",
    "    y_col='label', #column with the labels\n",
    "    subset='training',#specifications for training\n",
    "    batch_size=32,#batch size\n",
    "    seed=42,#random seed\n",
    "    shuffle=True,#shuffles the seed\n",
    "    class_mode='categorical',#the labels are categorical\n",
    "    target_size=image_expected#uses the target size indicated\n",
    ")\n",
    "#creates a generator for the validation data \n",
    "valid_generator = training_generator.flow_from_dataframe(\n",
    "    dataframe=training_df,#holds labels\n",
    "    directory='./',  #where images are located\n",
    "    x_col='cropped_img',  #column of the file path\n",
    "    y_col='label',  #column with the labels\n",
    "    subset='validation',#specifications for training\n",
    "    batch_size=32,#batch size\n",
    "    seed=42,#random seed\n",
    "    shuffle=True,#shuffles the seed\n",
    "    class_mode='categorical',#the labels are categorical\n",
    "    target_size=image_expected#uses the target size indicated\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescales the images to a range of [0,1]\n",
    "test_images= ImageDataGenerator(rescale = 1./255.)\n",
    "#creates a generator for the testing data.\n",
    "test_generator= training_generator.flow_from_dataframe(\n",
    "    \n",
    "    dataframe=test_df,#datafram that holds the testing data\n",
    "    directory='./',   #where images are located\n",
    "    x_col='cropped_img',  #column of the file path\n",
    "    y_col='label',#column with the labels\n",
    "    batch_size=32,#batch size\n",
    "    seed=42,#random seed\n",
    "    shuffle=True,#shuffles the seed\n",
    "    class_model= 'categorical',#the labels are categorical\n",
    "    target_size=image_expected#uses the target size indicated\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "#code that will be altered for each model\n",
    "#this is an example model that has 3 hidden layers\n",
    "#this investigation will alter the number of hidden layers\n",
    "\n",
    "\n",
    "#uses a linear stack of layers \n",
    "#keras model\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    #input layer is implied\n",
    "    keras.layers.Conv2D(filters=10, kernel_size=3, activation='relu', input_shape=shape),#hidden layer 1 \n",
    "    keras.layers.MaxPool2D(pool_size=2, padding='valid'),#not counted as a hidden layer\n",
    "    keras.layers.Flatten(),#hidden layer 2\n",
    "    keras.layers.Dense(units=len(classes), activation='softmax')#hidden layer 3\n",
    "    #output layer is implied\n",
    "])\n",
    "\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compules the model with the with the Adam optimizer\n",
    "#calculates the loss\n",
    "#accurary and \n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "               loss='categorical_crossentropy',\n",
    "               \n",
    "               metrics=['accuracy', keras.metrics.Recall()])\n",
    "               #recal \n",
    "\n",
    "#imports the time module\n",
    "import time\n",
    "\n",
    "# Record the start time before the module begins\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the models using the train_genertor and validates it runs for 10 epochs\n",
    "history1 = model.fit(train_generator, epochs=10, steps_per_epoch=len(train_generator),\n",
    "                      validation_data=valid_generator, validation_steps=len(valid_generator))\n",
    "\n",
    "# Records the end time after the module ends\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the total time taken for training\n",
    "total_time = end_time - start_time\n",
    "print(\"Total time taken for training:\", total_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a dataframe with the results\n",
    "result1=pd.DataFrame(history1.history)\n",
    "result1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result2.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)\n",
    "#evaluates the trained models performance outputs accuracy, loss, and recall\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
